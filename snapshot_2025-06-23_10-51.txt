from fastapi import APIRouter, Request
from telegram import Update
from telegram.ext import (
    Application, ContextTypes, AIORateLimiter,
    CommandHandler, MessageHandler, filters
)
import os, uuid, mimetypes, aiofiles

from app.firestore_client import (
    save_dialog, get_dialog_page, set_topic, get_topic
)
from app.storage_client import put_file
from app.openai_client import ask_gpt

router = APIRouter()
TOKEN = os.environ["TELEGRAM_TOKEN"]


async def cmd_topic(update: Update, ctx: ContextTypes.DEFAULT_TYPE):
    if not ctx.args:
        await update.message.reply_text("usage: /topic <name>")
        return
    await set_topic(str(update.effective_user.id), ctx.args[0])
    await update.message.reply_text("âœ“ Topic switched to " + ctx.args[0])


async def cmd_history(update: Update, ctx: ContextTypes.DEFAULT_TYPE):
    uid = str(update.effective_user.id)
    page = await get_dialog_page(uid, 0)
    txt = "\n\n".join(f"ðŸ’¬ {d['user']}\nðŸ¤– {d['bot']}" for d in page) or "â€” empty â€”"
    await update.message.reply_text(txt)


async def cmd_upload(update: Update, ctx: ContextTypes.DEFAULT_TYPE):
    if not update.message or not update.message.document:
        await update.message.reply_text("Attach a file with /upload")
        return
    doc = update.message.document
    raw = await (await ctx.bot.get_file(doc.file_id)).download_as_bytearray()
    ext = os.path.splitext(doc.file_name)[1]
    name = f"{uuid.uuid4().hex}{ext}"
    url = await put_file(name, bytes(raw))
    await update.message.reply_text(f"âœ“ uploaded â†’ {url}")


async def text_handler(update: Update, ctx: ContextTypes.DEFAULT_TYPE):
    uid = str(update.effective_user.id)
    topic = await get_topic(uid) or "default"
    reply = await ask_gpt(update.message.text, topic)
    await save_dialog(uid, update.message.text, reply)
    await update.message.reply_text(reply)


async def build_app(token: str):
    app = (
        Application.builder()
        .token(token)
        .rate_limiter(AIORateLimiter())
        .build()
    )

    app.add_handler(CommandHandler("topic", cmd_topic))
    app.add_handler(CommandHandler("history", cmd_history))
    app.add_handler(CommandHandler("upload", cmd_upload))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, text_handler))

    await app.initialize()
    return app


@router.post("/webhook/telegram")
async def webhook(req: Request):
    upd = Update.de_json(await req.json(), None)
    await req.app.state.tg_app.process_update(upd)
    return {"ok": True}

import os, datetime
from google.cloud.firestore import AsyncClient   

_db: AsyncClient | None = None


def _get_db() -> AsyncClient:
    global _db
    if _db is None:
        _db = AsyncClient()
    return _db


async def save_dialog(uid: str, user_msg: str, bot_msg: str):
    col = _get_db().collection("dialogs").document(uid).collection("msgs")
    ts = datetime.datetime.utcnow()
    await col.add({"user": user_msg, "bot": bot_msg, "ts": ts})


async def get_dialog_page(uid: str, page: int, size: int = 10):
    col = (
        _get_db()
        .collection("dialogs")
        .document(uid)
        .collection("msgs")
        .order_by("ts", direction="DESCENDING")
        .limit(size)
        .offset(page * size)
    )
    docs = await col.get()
    return [d.to_dict() for d in docs]


async def set_topic(uid: str, topic: str):
    await _get_db().collection("topics").document(uid).set({"topic": topic})


async def get_topic(uid: str):
    doc = await _get_db().collection("topics").document(uid).get()
    return (doc.to_dict() or {}).get("topic")

from app.firestore_client import _db

_topic_cache: dict[str, str] = {}


async def set_topic(user_id: str, topic: str) -> None:
    _topic_cache[user_id] = topic
    await _db.collection("users").document(user_id).set({"topic": topic})


async def get_topic(user_id: str) -> str:
    if user_id in _topic_cache:
        return _topic_cache[user_id]
    doc = await _db.collection("users").document(user_id).get()
    topic = doc.to_dict().get("topic", "default") if doc.exists else "default"
    _topic_cache[user_id] = topic
    return topic

# app/main.py
from fastapi import FastAPI

# Telegram webhook routes
from app.telegram_adapter import router as tg_router

app = FastAPI()
app.include_router(tg_router)

from google.cloud.storage import Client
from uuid import uuid4
import mimetypes, os, asyncio

_BUCKET = os.environ["GCS_BUCKET"]
_PUBLIC = f"https://storage.googleapis.com/{_BUCKET}"
_client: Client | None = None


def _get_client():
    global _client
    if _client is None:
        _client = Client()
    return _client


async def put_file(name: str, data: bytes) -> str:
    loop = asyncio.get_running_loop()
    await loop.run_in_executor(None, _upload_sync, name, data)
    return f"{_PUBLIC}/{name}"


def _upload_sync(name: str, data: bytes):
    blob = _get_client().bucket(_BUCKET).blob(name)
    blob.upload_from_string(data, content_type=mimetypes.guess_type(name)[0] or "application/octet-stream")

import io
import PyPDF2


def read_txt(data: bytes) -> str:
    return data.decode("utf-8", errors="ignore")


def read_pdf(data: bytes) -> str:
    reader = PyPDF2.PdfReader(io.BytesIO(data))
    pages = [p.extract_text() or "" for p in reader.pages]
    return "\n".join(pages)

import os, openai, asyncio

MODEL = os.getenv("OPENAI_MODEL", "gpt-4o-mini")
openai.api_key = os.environ["OPENAI_KEY"]


async def ask_gpt(prompt: str, topic: str) -> str:
    loop = asyncio.get_running_loop()
    resp = await loop.run_in_executor(
        None,
        lambda: openai.chat.completions.create(
            model=MODEL,
            messages=[
                {"role": "system", "content": f"topic: {topic}"},
                {"role": "user", "content": prompt},
            ],
            max_tokens=512,
        ),
    )
    return resp.choices[0].message.content.strip()

import io
from typing import Literal

import PyPDF2
from app.openai_client import ask_gpt


def _pdf_to_text(data: bytes) -> str:
    reader = PyPDF2.PdfReader(io.BytesIO(data))
    return "\n".join(page.extract_text() or "" for page in reader.pages)


def _plain_to_text(data: bytes, ext: Literal[".txt", ".md"]) -> str:
    return data.decode("utf-8", errors="ignore")


def _bytes_to_text(data: bytes, filename: str) -> str:
    filename = filename.lower()
    if filename.endswith(".pdf"):
        return _pdf_to_text(data)
    if filename.endswith((".txt", ".md")):
        return _plain_to_text(data, ".txt")
    raise ValueError("Unsupported file type for summarization")


async def summarize(file_bytes: bytes, filename: str) -> str:
    """
    Returns a concise summary (â‰ˆ 200 words) of the document.
    """
    text = _bytes_to_text(file_bytes, filename)[:10_000]  # safety cutoff
    prompt = (
        "Summarize the following document in ~200 words, preserving structure:\n\n"
        f"{text}"
    )
    # user_id is irrelevant for system-level summarization â†’ pass placeholder
    return await ask_gpt("summary", prompt)

fastapi
uvicorn[standard]
python-telegram-bot[async,rate-limiter]==20.8
openai==0.28.1
google-cloud-firestore>=2.11.0
google-auth>=2.22.0
google-cloud-storage>=2.16.0
aiofiles
python-multipart
PyPDF2>=3.0.0
PyPDF2>=3.0.1

local_uploads/

